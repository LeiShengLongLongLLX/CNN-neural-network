# CNN(Covlution Neural Network)

## 一、CNN总概

### 1.1 CNN是什么？

*   **定义**：卷积神经网络是一种专为处理**网格状数据**（如图像、视频、音频）而设计的深度学习模型。
*   **核心思想**：通过**卷积** 操作来自动、高效地学习数据的空间层次特征。
*   **与传统神经网络的对比**：
    *   **传统神经网络（如全连接网络）**：将输入数据（如图像）展平为一维向量，会完全丢失空间信息，且参数数量巨大，容易过拟合。
    *   **CNN**：保留了数据的空间结构，通过**局部连接**和**权值共享** 大大减少了参数数量，使其更高效、更易于训练。

### 1.2 为什么CNN特别适合图像处理？

1.  **局部相关性**：图像中一个像素与其周围像素的关系最紧密，与遥远像素的关系较弱。CNN的卷积操作正是关注局部区域。
2.  **平移不变性**：无论一只猫在图像的左上角还是右下角，它都是一只猫。CNN通过池化操作和层级结构，使得网络对目标的位置变化不敏感。
3.  **尺度不变性**：通过多层卷积和池化，CNN可以从底层边缘、纹理，到中层部分器官，再到高层整体物体，逐步构建出对图像的尺度鲁棒性理解。

---

### 1.3 CNN的核心组件

一个典型的CNN由以下几部分组成：

#### 1.3.1 卷积层 - 特征提取的核心

*   **目的**：使用**滤波器（或称为卷积核）** 在输入数据上滑动，提取局部特征（如边缘、角点、颜色块）。
*   **关键概念**：
    *   **滤波器**：一个小尺寸的权重矩阵（如3x3, 5x5）。不同的滤波器用于提取不同的特征。
    *   **感受野**：滤波器在输入图像上每次覆盖的区域大小。
    *   **步长**：滤波器每次移动的像素数。步长越大，输出特征图尺寸越小。
    *   **填充**：在输入图像边缘填充一圈像素（通常用0填充）。目的是为了控制输出特征图的尺寸。
    *   **深度**：一个卷积层通常使用多个滤波器，每个滤波器会产生一个**特征图**。所有这些特征图堆叠起来，就构成了该卷积层的输出。
*   **工作机制**：滤波器在输入上滑动，在每个位置进行**点乘** 求和，再加上一个偏置项，最终生成特征图。

#### 1.3.2 激活函数 - 引入非线性

*   **目的**：为网络引入非线性因素，使其能够学习并模拟复杂的非线性关系。没有它，多层网络就等价于一个单层线性模型。
*   **常用函数**：
    *   **ReLU（修正线性单元）**：`f(x) = max(0, x)`。目前最常用，因为它能有效缓解梯度消失问题，且计算简单。
    *   **Sigmoid / Tanh**：在早期使用，现在多用于输出层（如二分类）。

#### 1.3.3 池化层 - 降维和保持平移不变性

*   **目的**：对特征图进行**下采样**，减少数据尺寸和参数量，防止过拟合，同时扩大后续卷积层的感受野，并赋予网络一定的平移不变性。
*   **特点**：没有需要学习的参数。
*   **常用方法**：
    *   **最大池化**：取池化窗口内的最大值。效果最好，最常用。
    *   **平均池化**：取池化窗口内的平均值。
*   **工作机制**：类似卷积，有一个窗口和步长，在特征图上滑动，但执行的是最大或平均操作。

#### 1.3.4. 全连接层 - 最终分类

*   **目的**：位于网络的末端，将前面学习到的所有分布式特征映射到最终的样本标签空间（进行分类或回归）。
*   **工作机制**：将最后一层卷积或池化输出的多维特征图**展平** 成一个一维向量，然后像传统神经网络一样进行连接。通常最后会接一个**Softmax** 函数，输出每个类别的概率。

**总结表**

| 组件 | 主要功能 | 关键优势 |
| :--- | :--- | :--- |
| **卷积层** | 提取局部空间特征 | 权值共享、局部连接，大幅减少参数 |
| **激活函数** | 引入非线性 | 使网络能拟合复杂函数（ReLU最常用） |
| **池化层** | 下采样，压缩特征图 | 降维、防止过拟合、提供平移不变性 |
| **全连接层** | 将特征映射到样本标签 | 完成最终的分类或回归任务 |

---

### 1.4 经典的CNN网络架构

*   **LeNet-5 (1998)**：CNN的开山之作，用于手写数字识别，结构为：`卷积 -> 池化 -> 卷积 -> 池化 -> 全连接 -> 输出`。
*   **AlexNet (2012)**：在ImageNet大赛中一战成名，真正开启了深度学习热潮。它更深，使用了ReLU、Dropout等技术。
*   **VGGNet (2014)**：探索了网络深度，通过堆叠小的3x3卷积核来替代大的卷积核，结构非常规整。
*   **GoogLeNet (2014)**：引入了**Inception模块**，在增加网络深度和宽度的同时，减少了参数量。
*   **ResNet (2015)**：提出了**残差块** 和**跳跃连接**，解决了极深网络的梯度消失和退化问题，使得构建上百甚至上千层的网络成为可能。
*   **MobileNet (2017)**：引入了**深度可分离卷积**为核心构建块，专为移动和嵌入式设备等资源受限环境设计，在速度和体积上实现了极致优化。
*   **YOLO (2016)**：**You Only Look Once** 的缩写，是目标检测领域的革命性框架。它将检测任务视为一个回归问题，实现了端到端的训练和极快的推理速度，催生了一系列实时检测应用。其核心思想是使用CNN骨干网络进行特征提取，再通过检测头直接预测边界框和类别概率。

---

### 1.5 CNN的工作流程总结

1.  **输入**：原始图像。
2.  **特征提取（前向传播）**：
    *   图像经过多个 **“卷积 -> 激活 -> 池化”** 的模块。
    *   底层网络学习到**低级特征**（边缘、颜色）。
    *   中层网络学习到**中级特征**（纹理、部分器官）。
    *   高层网络学习到**高级特征**（整体物体，如“猫 脸”、“车轮”）。
3.  **分类**：高级特征被送入**全连接层**，最终通过**Softmax**输出每个类别的概率。
4.  **训练（反向传播）**：
    *   计算预测结果与真实标签的**损失**。
    *   使用**优化器（如SGD, Adam）**，通过**反向传播**算法，将损失误差从后向前传递，并更新网络中所有滤波器和权重参数。
    *   重复此过程，直到模型收敛。

---

### 1.6 CNN的应用领域（远超图像）

*   **计算机视觉**：图像分类、目标检测、图像分割、人脸识别。
*   **自然语言处理**：文本分类、情感分析、机器翻译（通过一维卷积处理序列）。
*   **游戏与机器人**：AlphaGo下围棋，机器人导航。
*   **医疗**：医学影像分析（CT、MRI片子诊断）。

---

## 二、Lenet5卷积神经网络

### 2.1 背景介绍

LeNet-5 是由 Yann LeCun 等人在1998年提出的卷积神经网络（CNN）模型，最初用于手写数字识别（MNIST 数据集）。它是现代深度学习中经典的卷积神经网络雏形，对后续的CNN发展有重要影响。

---

### 2.2 网络架构

LeNet-5 主要由以下几部分组成：

| 层名称 | 类型   | 输入尺寸         | 输出尺寸         | 参数说明              | 参数数量（含偏置） |
| --- | ---- | ------------ | ------------ | ----------------- | --------- |
| 输入层 | —    | 1 × 32 × 32  | 1 × 32 × 32  | 灰度图像输入            | 0         |
| C1  | 卷积层  | 1 × 32 × 32  | 6 × 28 × 28  | 6个卷积核，大小5×5，步长1   | 156       |
| S2  | 池化层  | 6 × 28 × 28  | 6 × 14 × 14  | 平均池化，窗口2×2，步长2    | 0         |
| C3  | 卷积层  | 6 × 14 × 14  | 16 × 10 × 10 | 16个卷积核，大小5×5，部分连接 | 2,416     |
| S4  | 池化层  | 16 × 10 × 10 | 16 × 5 × 5   | 平均池化，窗口2×2，步长2    | 0         |
| C5  | 卷积层  | 16 × 5 × 5   | 120 × 1 × 1  | 120个卷积核，大小5×5，全连接 | 48,120    |
| F6  | 全连接层 | 120          | 84           | 全连接层              | 10,164    |
| 输出层 | 全连接层 | 84           | 10           | 对应10类数字的输出        | 850       |

---

### 2.3 各层功能及原理详解

#### 1. 输入层

* 输入为 32×32 像素的灰度图像（单通道），
* 原始MNIST图像为28×28，LeNet-5采用了32×32的输入尺寸，方便边缘处理。

#### 2. C1卷积层

* 使用6个5×5卷积核，对输入进行卷积操作，步长为1，
* 输出6个28×28的特征图（通道），
* 参数总数计算：

$$
5 \times 5 \times 1 \times 6 + 6 = 150 + 6 = 156
$$

* 功能：提取图像的局部特征，如边缘、纹理。

#### 3. S2池化层（子采样层）

* 对每个通道做平均池化，窗口大小2×2，步长2，

* 输出特征图尺寸减半，变为6×14×14，

* 无需学习参数。

* 功能：降低特征图尺寸，减少计算量和过拟合风险，同时增强平移不变性。

#### 4. C3卷积层（部分连接卷积层）

* 有16个5×5卷积核，输入通道为6，
* 采用“部分连接”，不是每个输出通道都连接所有输入通道，减少参数量和计算，
* 输出16个10×10特征图。
* 参数总数计算：

$$
5 \times 5 \times 6 \times 16 + 16 = 2400 + 16 = 2,416
$$

* 功能：提取更复杂的组合特征，部分连接提升表达能力同时控制参数规模。

#### 5. S4池化层

* 结构与S2相同，平均池化，窗口2×2，步长2，

* 输出16×5×5特征图。

* 作用同S2，进一步降低尺寸和参数。

#### 6. C5卷积层（全连接卷积层）

* 卷积核大小为5×5，输入16个通道，
* 因为输入特征图为5×5，卷积后输出为1×1，
* 实际上等价于全连接层，输出120个神经元。
* 参数总数计算：

$$
5 \times 5 \times 16 \times 120 + 120 = 48,000 + 120 = 48,120
$$

* 功能：综合所有特征，形成高层次表达。

#### 7. F6全连接层

* 输入120个神经元，输出84个神经元，
* 参数总数计算：

$$
120 \times 84 + 84 = 10,080 + 84 = 10,164
$$

* 作用是进一步整合高层特征。

#### 8. 输出层

* 84维输入，10维输出，
* 对应10个数字类别的得分（logits），
* 参数总数计算：

$$
84 \times 10 + 10 = 840 + 10 = 850
$$

---

### 2.4 LeNet-5的核心原理

* **局部感受野**：卷积核只看输入局部区域，提取局部特征。
* **权值共享**：同一个卷积核在整个输入空间滑动，减少参数。
* **下采样（池化）**：降低特征图尺寸，提升平移不变性，减少计算量。
* **层级特征抽取**：从简单边缘到复杂结构的逐层特征学习。
* **部分连接**：C3层部分连接设计，平衡表达能力和参数规模。
* **端到端训练**：通过反向传播联合优化所有参数。

---

### 2.5 LeNet-5的影响和局限

#### 影响

* 是最早成功应用于图像识别的CNN架构之一，
* 为后续更深层、更复杂的网络（如AlexNet、VGG、ResNet）奠定基础。

#### 局限

* 网络较浅，容量有限，难以处理复杂大规模数据集，
* 只适合灰度小图像，未用批量归一化、激活函数优化等现代技术。

---

### 2.6 总结

| 优点         | 局限               |
| ---------- | ---------------- |
| 参数少，训练快    | 深度和宽度有限          |
| 结构简单，易理解   | 表达能力有限           |
| 权值共享、局部感受野 | 未使用现代优化技术（如ReLU） |

---

### 2.7 LeNet-5 总参数量

所有可训练参数加起来约为：

$$
156 + 0 + 2,416 + 0 + 48,120 + 10,164 + 850 = 61,706
$$

**总参数量约 61,706 个。**

---

### 2.8 参考资料

* Yann LeCun, et al., “Gradient-Based Learning Applied to Document Recognition,” Proceedings of the IEEE, 1998.
* PyTorch官方文档及LeNet-5代码实现示例。

---

## 三、Yolo

---

## 四、MobileNet

### 4.1 为什么要有 MobileNet？

传统 CNN（如 VGG、ResNet）计算量非常大，特别是普通卷积：

* 参数量高
* FLOPs 大
* 部署成本高
* 不适合手机、嵌入式、边缘设备

**MobileNet 的目标：**

> 在保证精度的情况下，大幅降低参数量和计算量，让 CNN 能在手机端轻松运行。

---

### 4.2 核心思想：Depthwise Separable Convolution（深度可分离卷积）

MobileNet 的关键创新，就是 **把普通卷积拆成两步**：

---

#### 4.2.1 普通卷积 Conv2D 的问题

普通卷积计算复杂度：

$$
D_K^2 \cdot M \cdot N \cdot D_F^2
$$

这里$D_K$为卷积核尺寸大小，$D_F$为特征图尺寸大小

例如输入通道=32，输出通道=64，卷积核=3×3，则：

* 参数量 = 3×3×32×64
* 计算量巨大

---

#### 4.2.2 深度可分离卷积的结构

> 深度可分离卷积 = **Depthwise Conv（逐通道卷积） + Pointwise Conv（1×1卷积）**

---

#### **A. Depthwise Convolution（逐通道卷积）**

* 每个输入通道单独使用一个卷积核
* 不改变通道数
* 计算非常轻量

参数量：

$$
D_K^2 \cdot M
$$

---

#### **B. Pointwise Convolution（1×1卷积）**

* 用 1×1 卷积完成通道混合
* 决定输出通道数

参数量：

$$
M \cdot N
$$

---

#### 4.2.3 与普通卷积的计算量对比

普通卷积：

$$
D_K^2 \cdot M \cdot N
$$

深度可分离卷积：

$$
D_K^2 \cdot M + M \cdot N
$$

节省比率：

$$
\frac{
D_K^2 \cdot M \cdot N
}{
D_K^2 \cdot M + M \cdot N
}
\approx 8\text{~}9 \text{倍}
$$

**MobileNet 能比普通卷积快 8～9 倍，模型也更轻。**

---

### 4.3 MobileNet V1 架构特征

MobileNet V1（2017）第一次提出深度可分离卷积，结构非常简单：

* 输入：224×224
* 第一层为普通卷积（stride=2）
* 后续卷积全部用 **depthwise + pointwise**
* 使用 ReLU6（防止量化损失）
* 最终使用 1024 通道全连接分类

#### 参数量：

* 约 **4.2M 参数**
* FLOPs = **569M**（比 VGG16 的 15.5G 小 27 倍）

特点：

* 非常轻量
* 推理速度极快
* 适合移动端部署

---

### 4.4 MobileNet V2（2018）结构特征

V2 引入两个关键创新：

---

#### 4.4.1 线性瓶颈（Linear Bottleneck）

传统卷积最后使用非线性（ReLU），会损失信息。

MobileNetV2：

> 在低维空间使用 **线性层（无 ReLU）** 避免特征破坏。

---

#### 4.4.2 倒残差结构（Inverted Residual）

ResNet 残差块是“压缩 → 卷积 → 扩张”。

MobileNetV2 反过来：

> 先扩张通道 → depthwise → 压缩通道

好处：

* 特征信息保留更充分
* 计算量更低
* 支持轻量级残差结构

---

#### 4.4.3 MobileNetV2 的参数量

* 仅 **3.4M 参数**
* 300M FLOPs

比 V1 更快、更准。

---

### 4.5 MobileNet V3（2019）结构特征

采用 NAS（神经网络结构搜索）+ V2 结构改进：

---

#### **关键创新：**

#### Squeeze-and-Excitation (SE) 模块

增强通道注意力机制。

#### h-swish 激活函数

更高精度、更好量化兼容性。

#### 更优结构搜索

让网络结构自动最优。

#### 版本：

* MobileNetV3 **Small**（超轻量）
* MobileNetV3 **Large**（兼顾精度）

---

### 4.6 MobileNet V1 V2 V3 与 LeNet5 对比


| 项目           | **LeNet5**     | **MobileNet V1**         | **MobileNet V2**                   | **MobileNet V3**         |
| ------------ | -------------- | ------------------------ | ---------------------------------- | ------------------------ |
| **发表年份**     | 1998           | 2017                     | 2018                               | 2019                     |
| **主要任务**     | MNIST 手写数字识别   | ImageNet 分类              | ImageNet 分类、移动端部署                  | 自动化模型搜索 + 移动端 SOTA       |
| **输入大小**     | 32×32          | 224×224                  | 224×224                            | 224×224                  |
| **参数量**      | ~60K           | ~4.2M                    | ~3.4M                              | ~2.9M（最小版）               |
| **卷积方式**     | 普通卷积           | 深度可分离卷积（DW+PW）           | 倒残差结构（Inverted Residual）+ DW 卷积    | 加入 SE、h-swish、NAS 优化     |
| **网络特色**     | 简单的 CNN + 池化   | 将 3×3 卷积拆成 DW 和 PW，计算量极低 | 引入扩展层（Expand）与压缩层（Projection），提升精度 | 自动搜索结构（NAS）+ 更高效注意力（SE）  |
| **激活函数**     | tanh           | ReLU                     | ReLU6                              | h-swish（更平滑更高效）          |
| **是否使用残差结构** | 否              | 否                        | ✔ 是（Inverted Residual）             | ✔ 是（改进版 residual）        |
| **是否轻量化**    | 否              | ✔ 轻量化开山之作                | ✔ 更高效，精度提升                         | ✔ 性能/速度顶尖的轻量化模型          |
| **适用平台**     | CPU / GPU      | 手机、嵌入式、IoT               | 手机、IoT、实时推理                        | 手机 AI 芯片、IoT、边缘设备        |
| **主要贡献**     | 提出卷积池化框架       | 大幅减少计算量 & 参数             | 用更深结构提升精度                          | 在保证轻量化的同时提升精度到接近大型模型     |
| **创新结构**     | C1-S2-C3-S4-C5 | DW + PW 卷积               | Inverted Residual Block            | SE Block + h-swish + NAS |
| **计算量**      | 极低             | 569M FLOPs               | 300M FLOPs                         | 219M FLOPs（V3-large）     |


---

### 4.7 MobileNet 的优缺点

#### 优点

* 参数量极低（3~4M）
* FLOPs 小，速度快
* 适合手机、物联网、嵌入式
* 训练速度快
* 量化友好

---

#### 缺点

* 精度比不上 ResNet/ViT
* Depthwise Conv 对 GPU 不太友好（并行性差）
* 在高精度任务上不足
* 对训练超参数敏感

---

## 五、Resnet

---

## 六、VGG

---

## 七、